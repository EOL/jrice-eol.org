x-app: &default-app
  image: publishing
  restart: always
  environment: # NOTE: see https://docs.docker.com/compose/environment-variables/ for details.
    - RAILS_ENV
    - RAILS_MASTER_KEY
    - ELASTICSEARCH_URL=elasticsearch:9200
    - NODE_OPTIONS=--openssl-legacy-provider npm run start
  depends_on:
    - mysql
    - neo4j
    - memcached
    - redis
    - elasticsearch
  networks:
    - publishing_network

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.8.9
    container_name: publishing_elasticsearch
    restart: always
    environment:
      - bootstrap.memory_lock=true
      - cluster.name=eol-search-${RAILS_ENV}
      - "ES_JAVA_OPTS=-Xms4g -Xmx4g"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./templates/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - /data/publishing_elasticsearch/data:/var/data/elasticsearch
      - /data/publishing_elasticsearch/log:/var/log/elasticsearch
    ports:
      - 9200:9200
    networks:
      - publishing_network
  memcached:
    image: memcached
    container_name: publishing_memcached
    restart: always
    environment:
      - TZ=America/New_York
    command: memcached -m 4096m
    networks:
      - publishing_network
  neo4j:
    image: neo4j:4.2.3
    container_name: neo4j
    restart: always
    # NOTE: environment variables OVERRIDE the values in the config file!
    # Results are then applied to an artificial copy of the config in
    # $HOME/conf/neo4j.conf, which can be VERY confusing. Be aware.
    environment:
      - TZ=America/New_York
      - NEO4J_AUTH=neo4j/SomePasswordHere
      - NEO4J_dbms_memory_pagecache_size=34G
      - NEO4J_dbms_memory_heap_max__size=31500m
      - NEO4J_dbms_memory_heap_initial__size=31500m
      - NEO4J_cypher_query__max__allocations_size=4G
      - NEO4J_dbms_transaction_timeout=85s
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_directories_import=/exports
      - NEO4J_apoc_export_file_enabled=true
    volumes:
      - /data/neo4j/data:/data
      - /data/neo4j/logs:/logs
      - /data/neo4j/plugins:/plugins
      - /data/neo4j/exports:/exports
      - ./resources/templates/neo4j.conf:/conf/neo4j.conf
      - ./resources/templates/apoc.conf:/conf/apoc.conf
    networks:
      - publishing_network
    ports:
      - 7473:7473
      - 7474:7474
      - 7687:7687
  mysql:
    image: mysql:5.7.31
    container_name: eol_publishing_mysql_ENV
    restart: always
    environment:
      - TZ=America/New_York
      - MYSQL_ROOT_PASSWORD=SomethingReallySecure
      - MYSQL_DATABASE=eol_web_ENV
      - MYSQL_USER=admin
      - MYSQL_PASSWORD=SomethingSuperSecureHereToo
    volumes:
       - /u/data/eol_publishing_mysql_ENV:/var/lib/mysql
       - /u/data/eol_publishing_mysql_ENV_temp:/tmp
       - /u/data/eol_publishing_mysql_ENV_conf:/etc/mysql/conf.d/
    networks:
      - publishing_network
  redis: # WARNING: It's simpler to just skip persistence, but that means we lose the entire queue on restart.
    image: redis:6.0
    container_name: redis
    restart: always
    ports:
      - 6379:6379
    networks:
      - publishing_network
  app:
    <<: *default-app
    build:
      context: ..
    command: bundle exec rails s -p 9393 -b '0.0.0.0'
    volumes:
      - /data/publishing_web:/app/public/data
      - /data/publishing_web_log:/app/log
      - /data/publishing_web_private:/app/data
      - /eol/tmp/publishing:/tmp
    ports:
      - "9393"
  pub_sidekiq:
    <<: *default-app
    container_name: pub_sidekiq
    command: bundle exec sidekiq
    volumes: # NOTE: YES, it shares the data volumes with app, so it can serve the files that were processed here.
      - /data/publishing_web:/app/public/data
      - /data/publishing_jobs_log:/app/log
      - /data/publishing_web_private:/app/data
      - /eol/tmp/publishing_jobs:/tmp
  pub_crono:
    <<: *default-app
    container_name: pub_crono
    command: bundle exec crono
    volumes: # NOTE: YES, it shares the data volumes with app, so it can serve the files that were processed here.
      - /data/publishing_web:/app/public/data
      - /data/publishing_jobs_log:/app/log
      - /data/publishing_web_private:/app/data
      - /eol/tmp/publishing_jobs:/tmp
  pub_worker:
    <<: *default-app
    container_name: pub_worker
    command: /app/bin/work
    volumes: # NOTE: YES, it shares the data volumes with app, so it can serve the files that were processed here.
      - /data/publishing_web:/app/public/data
      - /data/publishing_jobs_log:/app/log
      - /data/publishing_web_private:/app/data
      - /eol/tmp/publishing_jobs:/tmp
  pub_data_worker:
    <<: *default-app
    container_name: pub_data_worker
    command: /app/bin/work_data
    volumes: # NOTE: YES, it shares the data volumes with app, so it can serve the files that were processed here.
      - /data/publishing_web:/app/public/data
      - /data/publishing_jobs_log:/app/log
      - /data/publishing_web_private:/app/data
      - /eol/tmp/publishing_jobs:/tmp
  pub_integrity_worker:
    <<: *default-app
    container_name: pub_integrity_worker
    command: /app/bin/work_integrity
    volumes: # NOTE: YES, it shares the data volumes with app, so it can serve the files that were processed here.
      - /data/publishing_web:/app/public/data
      - /data/publishing_jobs_log:/app/log
      - /data/publishing_web_private:/app/data
      - /eol/tmp/publishing_jobs:/tmp
  nginx:
    build:
      context: ..
      dockerfile: ./Dockerfile.nginx
    container_name: nginx
    volumes:
      - ../config/nginx.conf:/etc/nginx/nginx.conf:ro
      - /data/publishing_nginx_log:/var/log/nginx
    ports:
      - "3000:3000"
    depends_on:
      - app
networks:
  publishing_network:
    driver: bridge
